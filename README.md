# 🎲 Exercícios com PySpark no Databricks

Este repositório contém um notebook utilizado para praticar manipulação e análise de dados com **PySpark** dentro do ambiente **Databricks**.  

📂 O dataset utilizado é o **San Francisco Fire Department Calls**, disponível na pasta pública do Databricks:  
`/databricks-datasets/learning-spark-v2/sf-fire/sf-fire-calls.csv`

---

## 🎯 Objetivo
Este notebook foi feito para:  
- ✅ Treinar a leitura (ingestão), transformação e limpeza de dados em Spark.  
- ✅ Praticar funções SQL e agregações.  
- ✅ Responder a perguntas exploratórias sobre os dados (tipos de chamadas, atrasos, distribuição por bairros, etc.).  

---

## 📊 Conteúdo
As principais etapas incluem:  
- 📌 Renomear colunas para padronização.  
- 📌 Conversão de tipos de dados (datas, timestamps, numéricos).  
- 📌 Consultas exploratórias em DataFrames para responder perguntas, como:  
  - Quantos tipos de chamadas diferentes existem?  
  - Quais os atrasos médios nas respostas?  
  - Quais bairros tiveram mais ocorrências?  
  - Qual semana de 2018 teve mais chamados?  

---

## ℹ️ Observação
Este projeto não tem foco em visualização avançada ou modelo preditivo, mas sim no **exercício de consultas e transformações em Spark**.

---

<img width="1188" height="869" alt="image" src="https://github.com/user-attachments/assets/465d3126-91ee-4c9e-bfda-7148dbb4af52" />

<img width="916" height="794" alt="image" src="https://github.com/user-attachments/assets/0706994d-12e5-4132-8d43-761cd9150806" />


